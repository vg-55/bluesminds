---
title: Chat Completions
description: Generate chat completions using any supported AI model
---

# Chat *Completions*

Generate chat completions using any supported AI model.

## Endpoint

```
POST https://api.bluesminds.com/v1/chat/completions
```

## Request Body

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `model` | string | Yes | Model identifier (e.g., "gpt-4") |
| `messages` | array | Yes | Array of message objects |
| `temperature` | number | No | Sampling temperature (0-2) |
| `max_tokens` | number | No | Maximum tokens to generate |
| `stream` | boolean | No | Enable streaming responses |

## Example Request

```typescript
const response = await fetch('https://api.bluesminds.com/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer bm_live_your_api_key',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'gpt-4',
    messages: [
      {
        role: 'system',
        content: 'You are a helpful assistant.'
      },
      {
        role: 'user',
        content: 'What is the capital of France?'
      }
    ],
    temperature: 0.7,
    max_tokens: 500
  })
});

const data = await response.json();
console.log(data.choices[0].message.content);
```

## Example Response

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The capital of France is Paris."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 8,
    "total_tokens": 28
  }
}
```

## Supported Models

### OpenAI
- gpt-4
- gpt-4-turbo
- gpt-3.5-turbo

### Anthropic
- claude-opus-4.5 (Latest, most capable)
- claude-sonnet-4.5 (Latest, balanced)
- claude-haiku-4 (Latest, fastest)
- claude-3-opus
- claude-3-sonnet
- claude-3-haiku

### Google
- gemini-pro
- gemini-pro-vision

### Cohere
- command
- command-light

<Callout>
**Note:** Model availability and features may vary by provider. Check the [models endpoint](/docs/api/models) for the latest supported models.
</Callout>
