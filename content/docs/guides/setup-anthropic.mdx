---
title: Setting Up Anthropic Claude
description: Step-by-step guide to configure Anthropic Claude models in your BluesMinds gateway
---

# Setting Up Anthropic *Claude*

Complete guide to configure and use Anthropic Claude models through your BluesMinds gateway.

## Prerequisites

Before you begin, you need:

1. **Anthropic API Key** - Get one from [console.anthropic.com](https://console.anthropic.com)
2. **LiteLLM Server** - Running instance to proxy requests
3. **Admin Access** - To your BluesMinds gateway

## Step 1: Get Your Anthropic API Key

1. Visit [console.anthropic.com](https://console.anthropic.com)
2. Sign up or log in
3. Navigate to **API Keys** section
4. Click **Create Key**
5. Copy your API key (starts with `sk-ant-`)

<Callout type="warn">
**Keep your API key secure!** Never commit it to version control or share it publicly.
</Callout>

## Step 2: Configure LiteLLM Server

### Option A: Docker (Recommended)

Create a `litellm-config.yaml` file:

```yaml
model_list:
  # Claude Opus 4.5
  - model_name: anthropic/claude-opus-4-5-20251031
    litellm_params:
      model: claude-opus-4-5-20251031
      api_key: os.environ/ANTHROPIC_API_KEY
      api_base: https://api.anthropic.com

  # Claude Sonnet 4.5
  - model_name: anthropic/claude-sonnet-4-5-20250929
    litellm_params:
      model: claude-sonnet-4-5-20250929
      api_key: os.environ/ANTHROPIC_API_KEY
      api_base: https://api.anthropic.com

  # Claude Haiku 4
  - model_name: anthropic/claude-haiku-4-0-20250101
    litellm_params:
      model: claude-haiku-4-0-20250101
      api_key: os.environ/ANTHROPIC_API_KEY
      api_base: https://api.anthropic.com

  # Friendly aliases
  - model_name: claude-opus-4.5
    litellm_params:
      model: claude-opus-4-5-20251031
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-sonnet-4.5
    litellm_params:
      model: claude-sonnet-4-5-20250929
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-haiku-4
    litellm_params:
      model: claude-haiku-4-0-20250101
      api_key: os.environ/ANTHROPIC_API_KEY
```

Create a `.env` file:

```bash
ANTHROPIC_API_KEY=sk-ant-your-actual-key-here
```

Run LiteLLM with Docker:

```bash
docker run -d \
  --name litellm-anthropic \
  -p 4000:4000 \
  -v $(pwd)/litellm-config.yaml:/app/config.yaml \
  --env-file .env \
  ghcr.io/berriai/litellm:main-latest \
  --config /app/config.yaml
```

### Option B: Local Installation

Install LiteLLM:

```bash
pip install litellm[proxy]
```

Set environment variable:

```bash
export ANTHROPIC_API_KEY=sk-ant-your-actual-key-here
```

Run LiteLLM:

```bash
litellm --config litellm-config.yaml --port 4000
```

## Step 3: Verify LiteLLM is Running

Test the health endpoint:

```bash
curl http://localhost:4000/health
```

Expected response:

```json
{
  "status": "healthy"
}
```

List available models:

```bash
curl http://localhost:4000/models
```

You should see your configured Claude models in the response.

## Step 4: Add LiteLLM Server to BluesMinds

### Via Admin Panel

1. Go to `/admin/providers`
2. Click **Add Server**
3. Fill in the details:
   - **Name**: `Anthropic Primary`
   - **Base URL**: `http://localhost:4000` (or your server URL)
   - **API Key**: Leave empty if LiteLLM doesn't require auth
   - **Priority**: `1`
   - **Weight**: `1.0`
   - **Max Concurrent**: `100`
4. Click **Save**

### Via Setup Script

Use the automated setup script:

```bash
# Update the script with your LiteLLM URL
node scripts/setup-anthropic-provider.mjs
```

Edit the script first to set your LiteLLM server URL:

```javascript
servers: [
  {
    name: 'Anthropic Primary',
    base_url: 'http://localhost:4000',  // Your LiteLLM URL
    // ...
  }
]
```

## Step 5: Create Model Mappings

Map friendly names to Claude models:

### Via Admin Panel

1. Go to `/admin/models`
2. Click **Add Model Mapping**
3. Create mappings:

**For Claude Sonnet 4.5:**
- **Custom Name**: `claude-sonnet-4.5`
- **Provider**: Select your Anthropic server
- **Actual Model**: `anthropic/claude-sonnet-4-5-20250929`
- **Display Name**: `Claude Sonnet 4.5`
- **Priority**: `1`
- **Weight**: `1.0`

Repeat for Opus and Haiku.

### Via API

```bash
curl -X POST https://your-gateway.com/api/admin/models \
  -H "Authorization: Bearer YOUR_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "custom_name": "claude-sonnet-4.5",
    "provider_id": "your-server-id",
    "actual_model_name": "anthropic/claude-sonnet-4-5-20250929",
    "display_name": "Claude Sonnet 4.5",
    "priority": 1,
    "weight": 1.0,
    "is_active": true
  }'
```

## Step 6: Test Your Setup

### Test with cURL

```bash
curl -X POST https://your-gateway.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4.5",
    "messages": [
      {
        "role": "user",
        "content": "Hello! Can you confirm you are Claude?"
      }
    ]
  }'
```

### Test with JavaScript/TypeScript

```typescript
const response = await fetch('https://your-gateway.com/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    model: 'claude-sonnet-4.5',
    messages: [
      { role: 'user', content: 'Hello! Can you confirm you are Claude?' }
    ],
  }),
});

const data = await response.json();
console.log(data.choices[0].message.content);
```

### Test with Python

```python
import requests

response = requests.post(
    'https://your-gateway.com/v1/chat/completions',
    headers={
        'Authorization': 'Bearer YOUR_API_KEY',
        'Content-Type': 'application/json',
    },
    json={
        'model': 'claude-sonnet-4.5',
        'messages': [
            {'role': 'user', 'content': 'Hello! Can you confirm you are Claude?'}
        ],
    }
)

print(response.json()['choices'][0]['message']['content'])
```

## Troubleshooting

### Issue: "Model not found"

**Cause**: Model mapping doesn't exist or LiteLLM doesn't have the model configured.

**Solution**:
1. Check LiteLLM models: `curl http://localhost:4000/models`
2. Verify model mapping in `/admin/models`
3. Check LiteLLM config file has the model listed

### Issue: "Authentication failed"

**Cause**: Invalid or missing Anthropic API key.

**Solution**:
1. Verify your API key at [console.anthropic.com](https://console.anthropic.com)
2. Check LiteLLM has access to the environment variable:
   ```bash
   docker exec litellm-anthropic env | grep ANTHROPIC
   ```
3. Restart LiteLLM after updating the key

### Issue: "Connection refused"

**Cause**: LiteLLM server is not running or not accessible.

**Solution**:
1. Check if LiteLLM is running:
   ```bash
   docker ps | grep litellm
   # or
   curl http://localhost:4000/health
   ```
2. Check firewall rules if running on remote server
3. Verify the base URL in BluesMinds matches your LiteLLM URL

### Issue: "Rate limit exceeded"

**Cause**: Hitting Anthropic's rate limits.

**Solution**:
1. Check your usage at [console.anthropic.com](https://console.anthropic.com)
2. Upgrade your Anthropic plan if needed
3. Implement request queuing in your application
4. Set rate limits in BluesMinds: `/admin/settings`

### Issue: "Server is unhealthy"

**Cause**: LiteLLM server failing health checks.

**Solution**:
1. Check LiteLLM logs:
   ```bash
   docker logs litellm-anthropic
   ```
2. Run manual health check from BluesMinds server:
   ```bash
   curl -v http://your-litellm-url:4000/health
   ```
3. Verify network connectivity between BluesMinds and LiteLLM

### Issue: "Invalid model version"

**Cause**: Model version mismatch between gateway and Anthropic.

**Solution**:
1. Use date-specific model versions in LiteLLM config:
   - `claude-opus-4-5-20251031`
   - `claude-sonnet-4-5-20250929`
   - `claude-haiku-4-0-20250101`
2. Check Anthropic's latest model versions
3. Update your LiteLLM config accordingly

## Verification Checklist

âœ… Anthropic API key obtained and secured
âœ… LiteLLM server running and accessible
âœ… LiteLLM config includes Claude models
âœ… LiteLLM health check passes
âœ… LiteLLM models endpoint shows Claude models
âœ… BluesMinds server added to gateway
âœ… Server health check passes in admin panel
âœ… Model mappings created
âœ… Test request returns valid Claude response
âœ… Usage logged in `/dashboard/logs`
âœ… Analytics show "anthropic" provider

## Production Best Practices

### Security

1. **Use environment variables** for API keys:
   ```bash
   # Never hardcode keys
   ANTHROPIC_API_KEY=sk-ant-xxx
   ```

2. **Rotate keys regularly**:
   - Set reminder to rotate every 90 days
   - Use multiple keys for different environments

3. **Restrict network access**:
   ```bash
   # Only allow BluesMinds to access LiteLLM
   iptables -A INPUT -p tcp --dport 4000 -s BLUESMINDS_IP -j ACCEPT
   iptables -A INPUT -p tcp --dport 4000 -j DROP
   ```

### Monitoring

1. **Set up health checks**:
   - BluesMinds automatically monitors server health
   - Check `/admin/providers` for status

2. **Monitor usage**:
   - View logs: `/dashboard/logs`
   - Check analytics: `/admin/analytics`
   - Track costs: `/dashboard/billing`

3. **Set up alerts**:
   - Configure email alerts for server failures
   - Set budget alerts in Anthropic console

### Performance

1. **Use appropriate models**:
   - Haiku for simple tasks (fastest, cheapest)
   - Sonnet for general use (balanced)
   - Opus for complex reasoning (most capable)

2. **Enable streaming**:
   ```typescript
   {
     model: 'claude-sonnet-4.5',
     messages: [...],
     stream: true  // Better UX
   }
   ```

3. **Set reasonable timeouts**:
   - Haiku: 30s
   - Sonnet: 60s
   - Opus: 120s

### Scaling

1. **Multiple LiteLLM instances**:
   ```yaml
   # Add to BluesMinds
   - Anthropic Primary (priority: 1)
   - Anthropic Backup (priority: 2)
   ```

2. **Load balancing**:
   - Use weights to distribute load
   - Set max concurrent requests per server

3. **Multi-region deployment**:
   - Deploy LiteLLM in multiple regions
   - Route requests based on user location

## Next Steps

- Read the [Anthropic Guide](/docs/guides/anthropic) for usage best practices
- Check [Models Overview](/docs/guides/models) to choose the right model
- Review [API Reference](/docs/api/chat) for all available parameters
- Set up monitoring and alerts
- Configure rate limits and quotas
- Test failover scenarios

## Need Help?

- Check [Troubleshooting](#troubleshooting) section above
- Review LiteLLM logs for errors
- Test with direct Anthropic API to isolate issues
- Check BluesMinds logs: `/admin/audit`
- Join our community for support

## Example: Complete Setup

Here's a complete example from start to finish:

```bash
# 1. Create directory
mkdir anthropic-gateway && cd anthropic-gateway

# 2. Create LiteLLM config
cat > litellm-config.yaml << 'EOF'
model_list:
  - model_name: claude-sonnet-4.5
    litellm_params:
      model: claude-sonnet-4-5-20250929
      api_key: os.environ/ANTHROPIC_API_KEY
EOF

# 3. Create .env file
echo "ANTHROPIC_API_KEY=sk-ant-your-key-here" > .env

# 4. Start LiteLLM
docker run -d \
  --name litellm-anthropic \
  -p 4000:4000 \
  -v $(pwd)/litellm-config.yaml:/app/config.yaml \
  --env-file .env \
  ghcr.io/berriai/litellm:main-latest \
  --config /app/config.yaml

# 5. Test LiteLLM
curl http://localhost:4000/health

# 6. Test with BluesMinds
curl -X POST https://your-gateway.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4.5",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'

# 7. Monitor usage
echo "Visit https://your-gateway.com/dashboard/logs"
```

You're now ready to use Anthropic Claude through your BluesMinds gateway! ðŸŽ‰
